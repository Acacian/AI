import os
import json
import yaml
import logging
from kafka import KafkaConsumer
from triton_client import TritonClient
from kafka_utils import send_message

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¡œê¹… ë ˆë²¨ ì„¤ì •
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO").upper()
logging.basicConfig(
    level=LOG_LEVEL,
    format="%(asctime)s | TritonRouter | %(levelname)s | %(message)s"
)
logger = logging.getLogger("TritonRouter")

KAFKA_BROKER = "kafka:9092"
CONFIG_PATH = "triton/config.yml"
GROUP_ID = "ai_triton_router_group"
DONE_DIR = "models"

triton = TritonClient()

with open(CONFIG_PATH, 'r') as f:
    config = yaml.safe_load(f)

topic_model_map = config.get("topics", {})
next_topic_map = config.get("routing", {})

# done ì²´í¬ ìºì‹œ
model_ready_cache = set()
seen_unready_models = set()

def get_kafka_consumer(topics):
    return KafkaConsumer(
        *topics,
        bootstrap_servers=KAFKA_BROKER,
        value_deserializer=lambda v: json.loads(v.decode("utf-8")),
        auto_offset_reset="latest",
        enable_auto_commit=True,
        group_id=GROUP_ID,
    )

def is_valid_data(data: dict) -> bool:
    return (
        ("input" in data and isinstance(data["input"], list)) or
        ("bids" in data and "asks" in data)
    )

def is_model_ready(model_name: str, base_path: str = DONE_DIR) -> bool:
    if model_name in model_ready_cache:
        return True

    done_path = os.path.join(base_path, f"{model_name}.done")
    if os.path.exists(done_path):
        model_ready_cache.add(model_name)
        return True
    else:
        # âœ… ì²˜ìŒë§Œ ë¡œê·¸ ì¶œë ¥
        if model_name not in seen_unready_models:
            logger.debug(f"â¸ï¸ ëª¨ë¸ í•™ìŠµ ë¯¸ì™„ë£Œ (.done ì—†ìŒ): {model_name} â†’ ë©”ì‹œì§€ ë¬´ì‹œ")
            seen_unready_models.add(model_name)
        return False

def flatten_orderbook(bids, asks):
    def flatten(side): return [float(v) for pair in side[:20] for v in pair]
    return flatten(bids) + flatten(asks)

def consume_loop():
    topics = list(topic_model_map.keys())
    logger.info(f"ğŸ“¥ Kafka Consumer êµ¬ë… ì‹œì‘: {topics}")

    consumer = get_kafka_consumer(topics)

    for msg in consumer:
        topic = msg.topic
        data = msg.value
        model_name = topic_model_map.get(topic)

        if not model_name:
            logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” í† í”½: {topic}")
            continue

        if not is_model_ready(model_name):
            logger.debug(f"â¸ï¸ ëª¨ë¸ í•™ìŠµ ë¯¸ì™„ë£Œ (.done ì—†ìŒ): {model_name} â†’ ë©”ì‹œì§€ ë¬´ì‹œ")
            continue

        if not is_valid_data(data):
            logger.warning(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ ë°ì´í„° êµ¬ì¡°: {data}")
            continue

        try:
            # orderbook í˜•íƒœ ë³€í™˜
            if "bids" in data and "asks" in data:
                input_data = {"input": [flatten_orderbook(data["bids"], data["asks"])]}
            else:
                input_data = data

            result = triton.infer(model_name, input_data)
            logger.info(f"âœ… [{topic}] â†’ {model_name} ê²°ê³¼: {result}")

            next_topic = next_topic_map.get(topic)
            if next_topic:
                send_message(next_topic, {"input": result[0]})
                logger.info(f"ğŸ“¤ ê²°ê³¼ ì „ì†¡ â†’ {next_topic}: {result[0]}")
            else:
                logger.info(f"ğŸ”š ìµœì¢… ë‹¨ê³„: {topic}")

        except Exception as e:
            logger.error(f"âŒ ì¶”ë¡  ì‹¤íŒ¨: {topic} | {e}")
